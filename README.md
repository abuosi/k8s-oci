# K8S OCI

This project is based on project [ampernetacle](https://github.com/jpetazzo/ampernetacle) from [Jérôme Petazzoni](https://github.com/jpetazzo). Thank you very much !

The modifition on original project was to reduce the number of nodes to 3, and increase the vcpu quantity for master (2 vcpus) and increase the memory of nodes (8gb ram). 

## Getting started

1. Create an Oracle Cloud Infrastructure account just follow this [link](https://signup.cloud.oracle.com/?sourceType=_ref_coc-asset-opcSignIn&language=en_US]).
2. Have installed or [install kubernetes](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl).
3. Have installed or [install terraform](https://learn.hashicorp.com/tutorials/terraform/install-cli?in=terraform/oci-get-started).
4. Have installed or [install OCI CLI ](https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/cliinstall.htm).
5. Have installed or [install Helm](https://helm.sh/docs/intro/install/) 
6. Configure [OCI credentials](https://learn.hashicorp.com/tutorials/terraform/oci-build?in=terraform/oci-get-started).
7. Download this project and enter its folder.
8. `cd terraform`
9. `terraform init`
10. `terraform apply`

That's it!

At the end of the `terraform apply`, a `kubeconfig` file is generated
in this directory. To use your new cluster, you can do:

Linux
```bash
export KUBECONFIG=$PWD/kubeconfig
kubectl get nodes
```

Windows
```powershell
$env:KUBECONFIG="$pwd\kubeconfig"
kubectl get nodes
```

The command above should show you 3 nodes, named `node1` to `node3`.

You can also log into the VMs. At the end of the Terraform output
you should see a command that you can use to SSH into the first VM
(just copy-paste the command).

## Stopping the cluster

`terraform destroy`

## Implementation details

This Terraform configuration:

- generates an OpenSSH keypair and a kubeadm token
- deploys 3 VMs using Ubuntu 20.04
- uses cloud-init to install and configure everything
- installs Docker and Kubernetes packages
- runs `kubeadm init` on the first VM
- runs `kubeadm join` on the other VMs
- installs the Weave CNI plugin
- transfers the `kubeconfig` file generated by `kubeadm`
- patches that file to use the public IP address of the machine

## Cluster Customization

This steps is opitional, so you could use the stacks of your preference.

### 1. Install NGINX Ingress Controller

Execute the command 

``` bash
helm upgrade --install ingress-nginx ingress-nginx \
     --repo https://kubernetes.github.io/ingress-nginx \
     --namespace ingress-nginx --create-namespace
``` 

### 2. Install Cluster Monitoring Stack

- Clone the repository official of [kube-prometheus](https://github.com/prometheus-operator/kube-prometheus)
- Follow the installation instruction on `README` file
## Deploy Example Applications

The application files deployment are on folder `k8s`

```bash
cd k8s
```
### 1. Ingress Route

Instalation

```bash
kubectl create ns nginx-route
kubectl apply ./nginx-route -n nginx-route
```
Verify it is work

``` 
curl http://<<PUBLIC-IP-NODE>>:<<PORT-INGRESS>>/blue
curl http://<<PUBLIC-IP-NODE>>:<<PORT-INGRESS>>/green
```
### 2. Micro Service Example

Instalation

```bash
kubectl create ns micro-service
kubectl apply ./micro-service -n micro-service
```
Verify it is work

``` 
curl http://<<PUBLIC-IP-NODE>>:<<PORT-INGRESS>>/time
curl http://<<PUBLIC-IP-NODE>>:<<PORT-INGRESS>>/gateway
```

### 3. Java Quarkus Example

Instalation

```bash
kubectl create ns my-hostname
kubectl apply ./my-hostname -n my-hostname
```
Verify it is work

``` 
curl http://<<PUBLIC-IP-NODE>>:<<PORT-INGRESS>>/hello
```